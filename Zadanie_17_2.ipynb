{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e6aaec9-5abf-4a50-a5c4-b7cccf026b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\pzeleznicki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "C:\\Users\\pzeleznicki\\AppData\\Local\\Temp\\ipykernel_16648\\47160941.py:11: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  spam_dataset['Spam'] = spam_dataset['Spam'].replace(['ham', 'spam'], [0, 1])\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\pzeleznicki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pzeleznicki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\pzeleznicki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "import itertools\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "nltk.download('punkt')\n",
    "spam_dataset = pd.read_csv('spam.csv', encoding = \"ISO-8859-1\", usecols=[0, 1], names=['Spam', 'Text'], skiprows=1)\n",
    "spam_dataset['Spam'] = spam_dataset['Spam'].replace(['ham', 'spam'], [0, 1])\n",
    "\n",
    "def remove_puncation(text):\n",
    "    cleaned = ''.join([word for word in text if word not in string.punctuation])\n",
    "    return cleaned\n",
    "spam_dataset['Cleaned_Text'] = spam_dataset['Text'].apply(lambda x: remove_puncation(x))\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "def tokenize(text):\n",
    "\n",
    "    # Usunięcie wielkich liter\n",
    "    clean_text = text.lower()\n",
    "\n",
    "    # Tokenizacja\n",
    "    tokenized_text = nltk.word_tokenize(clean_text)\n",
    "    return tokenized_text\n",
    "\n",
    "spam_dataset['Tokenized_Text'] = spam_dataset['Cleaned_Text'].apply(lambda x: tokenize(x))\n",
    "\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    without_stopwords = [word for word in text if word not in stopwords]\n",
    "    return without_stopwords\n",
    "spam_dataset['WithoutStop_Text'] = spam_dataset['Tokenized_Text'].apply(lambda x: remove_stopwords(x))\n",
    "\n",
    "stemmer = nltk.PorterStemmer()\n",
    "def stemming(text):\n",
    "    stemmed_words = [stemmer.stem(word) for word in text]\n",
    "    return stemmed_words\n",
    "spam_dataset['Stemmed_Text'] = spam_dataset['WithoutStop_Text'].apply(lambda x: stemming(x))\n",
    "\n",
    "nltk.download('wordnet')\n",
    "lemmater = nltk.WordNetLemmatizer()\n",
    "def lemmatizing(text):\n",
    "    lemmatized_words = [lemmater.lemmatize(word) for word in text]\n",
    "    return lemmatized_words\n",
    "spam_dataset['Lemmatized_Text'] = spam_dataset['WithoutStop_Text'].apply(lambda x: lemmatizing(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50f90507-4936-4b1c-bda9-f6fb51e28756",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "X = spam_dataset['Lemmatized_Text']\n",
    "y = spam_dataset['Spam']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify =y)\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "# Uczysz słownik tylko na danych treningowych\n",
    "X_train_tfidf = tfidf.fit_transform(X_train.apply(lambda x: ' '.join(x)))\n",
    "\n",
    "# Przekształcasz testowe dane tylko transformem\n",
    "X_test_tfidf = tfidf.transform(X_test.apply(lambda x: ' '.join(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "977bd085-25ff-4178-b5e5-cd1a0569b584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8658290329818263"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "clf.score(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1535bfff-e722-4910-bf0f-b5cdfd29964c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8663677130044843"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4148d5a3-04c4-423c-8a3e-6c77a03aa84e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.874439461883408"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = clf.feature_importances_   #Sprawdza ważność cech z modelu\n",
    "feature_names = tfidf.get_feature_names_out()  #łaczy ważność z nazwami cech (słów)\n",
    "\n",
    "#Filtracja cech\n",
    "important_indices = [i for i in range(len(importances)) if importances[i] > 0.001]\n",
    "important_feature_names = [feature_names[i] for i in important_indices]\n",
    "\n",
    "#Selekcja cech w danych\n",
    "X_train_selected = X_train_tfidf[:, important_indices]\n",
    "X_test_selected = X_test_tfidf[:, important_indices]\n",
    "\n",
    "clf.fit(X_train_selected, y_train)\n",
    "clf.score(X_test_selected, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e7096d00-5f1a-4b58-8fca-5c20bc4237c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pzeleznicki\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: FitFailedWarning: \n",
      "540 fits failed out of a total of 1620.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "161 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pzeleznicki\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pzeleznicki\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"C:\\Users\\pzeleznicki\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\Users\\pzeleznicki\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "379 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pzeleznicki\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pzeleznicki\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"C:\\Users\\pzeleznicki\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\Users\\pzeleznicki\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\pzeleznicki\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.89252918 0.89208024 0.89320208\n",
      " 0.89252968 0.89252943 0.89297836 0.89185578 0.89185603 0.89275339\n",
      " 0.89028501 0.88849054 0.8914076  0.89006055 0.88871475 0.8914076\n",
      " 0.89028501 0.88983608 0.89073395 0.88736694 0.88893796 0.88916293\n",
      " 0.88736694 0.88893796 0.88916293 0.88736669 0.88893796 0.88893846\n",
      " 0.86582919 0.86582919 0.86582919 0.86582919 0.86582919 0.86582919\n",
      " 0.86582919 0.86582919 0.86582919 0.86582919 0.86582919 0.86582919\n",
      " 0.86582919 0.86582919 0.86582919 0.86582919 0.86582919 0.86582919\n",
      " 0.86582919 0.86582919 0.86582919 0.86582919 0.86582919 0.86582919\n",
      " 0.86582919 0.86582919 0.86582919        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.93627732 0.93784909 0.93672701 0.93560442 0.93807381 0.93627883\n",
      " 0.93762438 0.93829803 0.93784884 0.9331363  0.93470857 0.93358573\n",
      " 0.93448184 0.93493304 0.93403441 0.93470656 0.93515725 0.93403416\n",
      " 0.9304437  0.92954785 0.9297708  0.9304437  0.92954785 0.9297708\n",
      " 0.93021923 0.92887444 0.9290974  0.86627813 0.86582919 0.86582919\n",
      " 0.86627813 0.86582919 0.86582919 0.86627813 0.86582919 0.86582919\n",
      " 0.86582919 0.86582919 0.86582919 0.86582919 0.86582919 0.86582919\n",
      " 0.86582919 0.86582919 0.86582919 0.86582919 0.86582919 0.86582919\n",
      " 0.86582919 0.86582919 0.86582919 0.86582919 0.86582919 0.86582919\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.95647204 0.95714545 0.95534971\n",
      " 0.95534971 0.95736916 0.95624657 0.95669576 0.95759362 0.95669576\n",
      " 0.95198296 0.95400341 0.95333001 0.95153428 0.95467631 0.95333001\n",
      " 0.95288108 0.95534971 0.9537792  0.94637405 0.94906766 0.94884319\n",
      " 0.94637405 0.94906766 0.94884319 0.94704695 0.94974055 0.94906766\n",
      " 0.87637486 0.87076596 0.87031727 0.87525303 0.86986859 0.86941966\n",
      " 0.87502881 0.86964387 0.86986834 0.86582919 0.86582919 0.86582919\n",
      " 0.86582919 0.86582919 0.86582919 0.86582919 0.86582919 0.86582919\n",
      " 0.86582919 0.86582919 0.86582919 0.86582919 0.86582919 0.86582919\n",
      " 0.86582919 0.86582919 0.86582919        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.97397241 0.9744216  0.97487003 0.97397266 0.97419688 0.97487003\n",
      " 0.97397291 0.97464531 0.97509399 0.97105635 0.9710556  0.96970955\n",
      " 0.97128032 0.97083113 0.97038245 0.97128057 0.97127981 0.97060742\n",
      " 0.96163126 0.96297781 0.96230491 0.96163126 0.96297781 0.96230491\n",
      " 0.96118258 0.96208019 0.96185573 0.96454832 0.9663433  0.96836351\n",
      " 0.96881118 0.96926037 0.96948483 0.96858697 0.97015849 0.97060717\n",
      " 0.86605366 0.86605366 0.86605366 0.86605366 0.86582919 0.86605366\n",
      " 0.86605366 0.86582919 0.86605366 0.86582919 0.86582919 0.86582919\n",
      " 0.86582919 0.86582919 0.86582919 0.86582919 0.86582919 0.86582919]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Najlepsze parametry:  {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "Dokładność na zbiorze testowym: 0.9803\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],  # Liczba drzew w lesie\n",
    "    'max_depth': [10, 20, 30, None],  # Głębokość drzewa\n",
    "    'min_samples_split': [2, 5, 10],  # Minimalna liczba próbek do podziału\n",
    "    'min_samples_leaf': [1, 2, 4],    # Minimalna liczba próbek w liściu\n",
    "    'max_features': ['auto', 'sqrt', 'log2']  # Liczba cech przy podziale\n",
    "}\n",
    "\n",
    "# Utworzenie modelu RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Inicjalizacja GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "\n",
    "grid_search.fit(X_train_tfidf, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Najlepsze parametry: \", best_params)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "test_score = best_model.score(X_test_tfidf, y_test)\n",
    "print(f\"Dokładność na zbiorze testowym: {test_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "070da762-54b3-4711-aaea-88398166dbd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['008704050406', '0089my', '0121', ..., 'ûï', 'ûïharry', 'ûò'],\n",
       "      shape=(7820,), dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f27d4b-887f-4a98-8887-c07f7168e3e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
